{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e801ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import db_password\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import pandas.io.sql as sqlio\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c07c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create database connection variable \n",
    "conn = psycopg2.connect(user=\"postgres\", password=db_password, host=\"localhost\", database=\"lichess_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc714d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute query and save it to a variable\n",
    "query=\"select * from chess_data\"\n",
    "chess_df = sqlio.read_sql_query(query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b8823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop extraneous id column\n",
    "chess_df.drop(['id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c71b14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split moves column into moves df\n",
    "moves_df = chess_df['moves'].str.split(' ', n=10, expand=True)\n",
    "\n",
    "# Drop column 10 and rename columns\n",
    "moves_df=moves_df.drop(10,axis=1)\n",
    "moves_df.columns= [\"Wm1\",\"Bm1\",\"Wm2\",\"Bm2\",\"Wm3\",\"Bm3\",\"Wm4\",\"Bm4\",\"Wm5\",\"Bm5\"]\n",
    "\n",
    "moves_df[\"outcome\"] = chess_df[\"winner\"]\n",
    "\n",
    "# drop na\n",
    "moves_df = moves_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b95aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wm1 Bm1 Wm2 Bm2 Wm3 Bm3 Wm4 Bm4 Wm5 Bm5 outcome "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wm1</th>\n",
       "      <th>Bm1</th>\n",
       "      <th>Wm2</th>\n",
       "      <th>Bm2</th>\n",
       "      <th>Wm3</th>\n",
       "      <th>Bm3</th>\n",
       "      <th>Wm4</th>\n",
       "      <th>Bm4</th>\n",
       "      <th>Wm5</th>\n",
       "      <th>Bm5</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>162</td>\n",
       "      <td>242</td>\n",
       "      <td>267</td>\n",
       "      <td>426</td>\n",
       "      <td>133</td>\n",
       "      <td>634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>150</td>\n",
       "      <td>184</td>\n",
       "      <td>30</td>\n",
       "      <td>411</td>\n",
       "      <td>282</td>\n",
       "      <td>330</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>144</td>\n",
       "      <td>99</td>\n",
       "      <td>283</td>\n",
       "      <td>392</td>\n",
       "      <td>370</td>\n",
       "      <td>105</td>\n",
       "      <td>489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "      <td>114</td>\n",
       "      <td>229</td>\n",
       "      <td>51</td>\n",
       "      <td>381</td>\n",
       "      <td>374</td>\n",
       "      <td>565</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>144</td>\n",
       "      <td>299</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>253</td>\n",
       "      <td>267</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wm1  Bm1  Wm2  Bm2  Wm3  Bm3  Wm4  Bm4  Wm5  Bm5  outcome\n",
       "0   17   14   60   34  162  242  267  426  133  634        1\n",
       "1   17   11   77  150  184   30  411  282  330  410        0\n",
       "2    3    7   36  144   99  283  392  370  105  489        1\n",
       "3   17   14   84  114  229   51  381  374  565   15        1\n",
       "4    3    7   84  144  299   11   16  253  267  639        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing moves to numbers\n",
    "for col in moves_df.columns:\n",
    "    print(col,end=' ')\n",
    "    \n",
    "    # Get list of unique values\n",
    "    values = list(set(moves_df[col].values))\n",
    "    \n",
    "    # Create numerical dictionary\n",
    "    values_with_indexes = {}\n",
    "    for i, v in enumerate(values):\n",
    "        values_with_indexes[v] = i\n",
    "    \n",
    "    # Replace column\n",
    "    moves_df.replace({col: values_with_indexes},inplace=True)\n",
    "\n",
    "moves_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4676791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv containing sample data to be imported into ML\n",
    "# moves_df.to_csv(\"ML_sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7775660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = moves_df[\"outcome\"].values\n",
    "X = moves_df.drop(\"outcome\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 1)\n",
    "number_input_features = len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6bfdf4",
   "metadata": {},
   "source": [
    "# Stage 1 - Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec165a",
   "metadata": {},
   "source": [
    "### Model 1: sigmoid input, sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fcd9556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4553fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0cd86fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6836 - acc: 0.4972\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa44f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818634756792873, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45ff92",
   "metadata": {},
   "source": [
    "### Model 2: relu input, sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d12f88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a544ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "70bb859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.9443 - acc: 0.4878\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7437 - acc: 0.4869\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7417 - acc: 0.4884\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7347 - acc: 0.4879\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7300 - acc: 0.4890\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dfea5af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6922 - acc: 0.4983\n",
      "Loss: 0.6922125508361225, Accuracy: 0.49832427501678467\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93283ffe",
   "metadata": {},
   "source": [
    "### Model 3: tanh input, sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4cfef554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c012f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6439059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6830 - acc: 0.4972\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fd3a070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818692683180706, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79faa84",
   "metadata": {},
   "source": [
    "### Model 4: sigmoid input, linear output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ce5b4328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "439e20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab4c148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6861 - acc: 0.4974\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6824 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6824 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6828 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6834 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "486f7115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6826 - acc: 0.4983\n",
      "Loss: 0.6825688758876884, Accuracy: 0.4983282685279846\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616cfdc6",
   "metadata": {},
   "source": [
    "### Model 5: relu input, linear output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1957ae38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fdeb9efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "38d1fe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 7.0347 - acc: 0.4899\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5239 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5240 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5240 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5240 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0135088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 6.5152 - acc: 0.4983\n",
      "Loss: 6.51520274151468, Accuracy: 0.49834415316581726\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6f567",
   "metadata": {},
   "source": [
    "### Model 6: tanh input, linear output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab1db215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "526af93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "66a40f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.9183 - acc: 0.4969\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6825 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6825 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6825 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6824 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1e967743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6820 - acc: 0.4983\n",
      "Loss: 0.6819516978605651, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0319b5",
   "metadata": {},
   "source": [
    "# Stage 1 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd6bc6",
   "metadata": {},
   "source": [
    "For the first stage of this analysis, we tried 6 models of varying parameters. The loss, accuracy scores, and parameters of our 6 models are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 2 | 0.6922 | 0.4983 | Relu input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 3 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 4 | 0.6826 | 0.4983 | Sigmoid input with 5 nodes, linear output, 5 epochs |\n",
    "| 5 | 6.5152 | 0.4983 | Relu input wiht 5 nodes, linear output, 5 epochs |\n",
    "| 6 | 0.6820 | 0.4983 | Tanh input with 5 nodes, linear output, 5 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3a887",
   "metadata": {},
   "source": [
    "The accuracy score for all 6 models was identical at 0.4983. An accuracy score of exactly 0.5 is the probability of randomly guessing the correct winner of a given game of chess, so the accuracy score of our models may reflect the difficulty of predicting a winner from only the first 10 moves of a game. Since games typically last far longer than 10 turns and the possible combinations of moves grow increasingly complex, this is not a surprising conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa3cfcf",
   "metadata": {},
   "source": [
    "Loss function, on the other hand, was not constant. The two models with relu inputs (Models 2 and 5) had the greatest loss score, indicating that the relu activation function is likely not the best choice for our model. Additionally, the models with sigmoid outputs (Models 1, 2, and 3) had lower loss functions than their counterpart models with linear outputs (Models 4, 5, and 6 respectively). This is expected, as output from a sigmoid function tends to be very close to either 0 or 1. We are posing a question with a binary answer, so a sigmoid function is the best choice for an activation function for our output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39143be",
   "metadata": {},
   "source": [
    "Given this information, our course of action for the final steps of completing this model will be to explore more varied input layers. This will be accomplished by varying the activation function (using sigmoid and tanh, leaving relu out), number of layers, number of nodes within each layer, and number of epochs used to train the model. We hypothesize that the sigmoid activation function will be the more appropriate choice for the input layer(s) for the same reasons it is the best choice for the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81278032",
   "metadata": {},
   "source": [
    "# Stage 2 - Refining the model by adding an additional input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42665815",
   "metadata": {},
   "source": [
    "### Model 7 - sigmoid + sigmoid input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf1655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mulle\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8200d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mulle\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9384a5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6822 - acc: 0.4975\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b718e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.681683825464082, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd4b5f",
   "metadata": {},
   "source": [
    "### Model 8 - sigmoid + tanh input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc1cf7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0e8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b47586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6826 - acc: 0.4974\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f50a3ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818749250321505, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f4ef7b",
   "metadata": {},
   "source": [
    "### Model 9 - tanh + sigmoid input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a7266b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08746ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfe356d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c31d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6816 - acc: 0.4983\n",
      "Loss: 0.6815962515790198, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e0f5b7",
   "metadata": {},
   "source": [
    "### Model 10 - tanh + tanh input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1f13a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a303ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3329a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6826 - acc: 0.4973\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24d114fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.6816705080182166, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1bc34",
   "metadata": {},
   "source": [
    "# Stage 2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8312d",
   "metadata": {},
   "source": [
    "The next step of our analysis was to determine whether adding an additional input layer would assist in lowering loss or raising accuracy in our model. The loss, accuracy, and parameters for Models 7-10 are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 7 | 0.6817 | 0.4983 | Two sigmoid input layers with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 8 | 0.6919 | 0.4983 | Sigmoid first input layer and tanh second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 9 | 0.6816 | 0.4983 | Tanh first input layer and sigmoid second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 10 | 0.6817 | 0.4983 | Two tanh input layers with 5 nodes each, sigmoid output, 5 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b8fd8",
   "metadata": {},
   "source": [
    "Accuracy continued to remain constant across all models, even when an additional input layer was added. Loss varied slightly, but not to a significant extent; the greatest difference in loss between the best models from Stage 1 and Stage 2 was 0.0003. As such, we can conclude that adding a second input layer is not likely to significantly improve the ability of our machine learning model to predict the winner of a chess game from the first 10 moves. Additionally, we cannot draw any further conclusions regarding the efficacy of the sigmoid and tanh activation functions in input layers given the very similar results between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30dc7a8",
   "metadata": {},
   "source": [
    "# Stage 3 - Refining the model by varying the number of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff2a11",
   "metadata": {},
   "source": [
    "### Model 11 - sigmoid input layer, 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb189a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=2, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "853a61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4519fb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6822 - acc: 0.4975\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4977\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2ed6972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.6817401380583206, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12fb055",
   "metadata": {},
   "source": [
    "### Model 12 - sigmoid input layer, 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aff5bccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d82ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65d4162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6838 - acc: 0.4972\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4977\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7243bdbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4984\n",
      "Loss: 0.6816825410157995, Accuracy: 0.4983521103858948\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e63791",
   "metadata": {},
   "source": [
    "### Model 13 - tanh input layer, 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea1c1bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=2, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12923ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea05298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6866 - acc: 0.4967\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3d0b904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6818 - acc: 0.4983\n",
      "Loss: 0.6818061287186948, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c722f",
   "metadata": {},
   "source": [
    "### Model 14 - tanh input layer, 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaaa44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4d2033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aaa00ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6844 - acc: 0.4973\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "111fbd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6818 - acc: 0.4983\n",
      "Loss: 0.6818064010055367, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99d5f0",
   "metadata": {},
   "source": [
    "# Stage 3 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e12e5",
   "metadata": {},
   "source": [
    "To determine whether the number of nodes affected the performance of our models, we ran single-layer models with varied numbers of nodes. The loss, accuracy, and parameters for Models 11-14 (as well as Models 1 and 3 for comparison) are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 11 | 0.6817 | 0.4983 | Sigmoid input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 12 | 0.6817 | 0.4984 | Sigmoid input with 8 nodes, sigmoid output, 5 epochs |\n",
    "| 3 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 13 | 0.6818 | 0.4983 | Tanh input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 14 | 0.6818 | 0.4983 | Tanh input with 8 nodes, sigmoid output, 5 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e6070a",
   "metadata": {},
   "source": [
    "Once again, loss and accuracy are more or less uniform. Model 12 is the first to show an accuracy score different from any other model, but a difference of 0.0001 is not significant. Given the results of Stage 3, we are unable to attribute number of nodes to model performance. Sigmoid and tanh input layers also continue to show no appreciable difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60463391",
   "metadata": {},
   "source": [
    "# Stage 4 - Refining the model by adjusting the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e67dd2a",
   "metadata": {},
   "source": [
    "### Model 15 - sigmoid input layer, 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "925d90db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2da4c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a9f69c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6830 - acc: 0.4975\n",
      "Epoch 2/2\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef66095c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.6817277191875162, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3127c2",
   "metadata": {},
   "source": [
    "### Model 16 - sigmoid input layer, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66e7cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a223214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbe9a1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6841 - acc: 0.4969\n",
      "Epoch 2/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 6/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 7/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 8/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6818 - acc: 0.4976\n",
      "Epoch 9/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4977\n",
      "Epoch 10/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a23e51ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6816 - acc: 0.4983\n",
      "Loss: 0.6815956441493135, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b8e3b",
   "metadata": {},
   "source": [
    "### Model 17 - tanh input layer, 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfa6e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02183cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b87f3a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6862 - acc: 0.4969\n",
      "Epoch 2/2\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4977\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "780fe825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818530754724361, Accuracy: 0.49834415316581726\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ee031",
   "metadata": {},
   "source": [
    "### Model 18 - tanh input layer, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36fad339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "510cb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59ad2c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6832 - acc: 0.4973\n",
      "Epoch 2/10\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 4/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 6/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 7/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 8/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 9/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 10/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01c641d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6818 - acc: 0.4983\n",
      "Loss: 0.6818354549266634, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405474a0",
   "metadata": {},
   "source": [
    "# Stage 4 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb720e01",
   "metadata": {},
   "source": [
    "Finally, we tested the effect of number of epochs on model performance. The loss, accuracy, and parameters for Models 15-18 (as well as Models 1 and 3 for comparison) are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 15 | 0.6817 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 16 | 0.6816 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 10 epochs |\n",
    "| 3 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 17 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 18 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 10 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74289308",
   "metadata": {},
   "source": [
    "As with all other parameters, adjusting the number of epochs had little to no impact on the performance of our machine learning models. Input function continued to show no impact as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1de0e7",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d32136",
   "metadata": {},
   "source": [
    "For reference, the loss, accuracy, and parameters for all models are shown again below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 2 | 0.6922 | 0.4983 | Relu input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 3 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 4 | 0.6826 | 0.4983 | Sigmoid input with 5 nodes, linear output, 5 epochs |\n",
    "| 5 | 6.5152 | 0.4983 | Relu input wiht 5 nodes, linear output, 5 epochs |\n",
    "| 6 | 0.6820 | 0.4983 | Tanh input with 5 nodes, linear output, 5 epochs |\n",
    "| 7 | 0.6817 | 0.4983 | Two sigmoid input layers with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 8 | 0.6919 | 0.4983 | Sigmoid first input layer and tanh second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 9 | 0.6816 | 0.4983 | Tanh first input layer and sigmoid second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 10 | 0.6817 | 0.4983 | Two tanh input layers with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 11 | 0.6817 | 0.4983 | Sigmoid input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 12 | 0.6817 | 0.4984 | Sigmoid input with 8 nodes, sigmoid output, 5 epochs |\n",
    "| 13 | 0.6818 | 0.4983 | Tanh input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 14 | 0.6818 | 0.4983 | Tanh input with 8 nodes, sigmoid output, 5 epochs |\n",
    "| 15 | 0.6817 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 16 | 0.6816 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 10 epochs |\n",
    "| 17 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 18 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 10 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e45eca",
   "metadata": {},
   "source": [
    "All four stages of this analysis showed that varying the parameters of our machine learning model had virtually no impact on both loss and accuracy. We were only able to draw conclusions regarding two of the five parameters examined: ruling out relu as an activation function and determining that sigmoid is the most appropriate output function. No conclusive evidence was found for the other three parameters. A summary of results can be found in the table below:\n",
    "\n",
    "| Parameter | Findings |\n",
    "| :---- | :--- | \n",
    "| Activation function | Relu ruled out, no evidence that either sigmoid or tanh is better than the other |\n",
    "| Output function | Sigmoid deemed better than linear |\n",
    "| Number of layers | No evidence that either 1 layer or 2 layers is better than the other |\n",
    "| Number of nodes | No evidence that any of 2, 5, or 8 nodes is better than the others |\n",
    "| Number of epochs | No evidence that any of 2, 5, or 10 epochs is better than the others |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29d482",
   "metadata": {},
   "source": [
    "All in all, the results of this study point to neural networks not being an effective means of predicting the winner of a game of chess given the first 10 moves. We supposed this was the case following the Stage 1 analysis, and Stages 2-4 supported the hypothesis. We cannot conclusively say that a neural network is entirely ineffective when trying to answer the question posed in this project since there are still many more combinations of parameters that could be tested, but the 18 models we examined gave us little reason to believe this is a path worth following.\n",
    "\n",
    "As previously stated, chess is a complex game. The possible outcomes are difficult to map as each individual move begets an exponentially branching tree of possibilities. Since games of chess tend to last far longer than 10 turns, our analysis is only able to scratch the surface. We were limited by a number of factors, most notably time and computing power. In theory, we could have extended our analysis far past the first 10 turns. However, adding an extra turn creates another branch on the tree and multiplies the number of computations necessary to perform this analysis. As such, we decided to examine whether determining a winner given 10 turns is possible with resources accessible to a wider range of people. Since accuracy scores remained very close to the probability of guessing a winner entirely at random throughout the entire project, the ultimate answer to our question is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b16e1b1",
   "metadata": {},
   "source": [
    "# Future Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09297e",
   "metadata": {},
   "source": [
    "The only type of machine learning used in this project was a neural network. While this method proved ineffective, other types of machine learning may be more useful in answering our question. For example, the flow of a game of chess closely mimics a quickly branching set of choices ultimately culminating in a winner. A decision tree may be an interesting way to map out chess games, though said tree would have to be almost impossibly large to accurately capture every possible combination of moves in a game of chess.\n",
    "\n",
    "Principal Component Analysis could possibly be used to incorporate more than 10 turns into the study without the number of input features reaching a problematically large number. This may be difficult given the qualitative nature of our input data, but it is an avenue to be explored.\n",
    "\n",
    "Finally, a repetition of our analysis with more input features could be performed given more time and access to faster computing. It is not realistic for a student using a personal computer to perform this analysis with the first 50 turns of a game of chess using a sufficiently large dataset since it would likely take too long and use up too many resources, but given enough time and computing power, this could either corroborate our conclusions or show that neural networks may be viable solution after all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
