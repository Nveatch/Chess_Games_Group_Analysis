{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e801ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "from config import db_password\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4d2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine\n",
    "db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/lichess_data\"\n",
    "engine = create_engine(db_string)\n",
    "conn=engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6e413f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>winner</th>\n",
       "      <th>white_id</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_id</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>rating_difference</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_name</th>\n",
       "      <th>moves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-31 20:06:40</td>\n",
       "      <td>13</td>\n",
       "      <td>white</td>\n",
       "      <td>bourgris</td>\n",
       "      <td>1500</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1191</td>\n",
       "      <td>309</td>\n",
       "      <td>D10</td>\n",
       "      <td>Slav Defense: Exchange Variation</td>\n",
       "      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4 Nc3 Ba5 Bf4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-30 21:53:20</td>\n",
       "      <td>16</td>\n",
       "      <td>black</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1322</td>\n",
       "      <td>skinnerua</td>\n",
       "      <td>1261</td>\n",
       "      <td>61</td>\n",
       "      <td>B00</td>\n",
       "      <td>Nimzowitsch Defense: Kennedy Variation</td>\n",
       "      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-30 21:53:20</td>\n",
       "      <td>61</td>\n",
       "      <td>white</td>\n",
       "      <td>ischia</td>\n",
       "      <td>1496</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1500</td>\n",
       "      <td>-4</td>\n",
       "      <td>C20</td>\n",
       "      <td>King's Pawn Game: Leonardis Variation</td>\n",
       "      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-30 16:20:00</td>\n",
       "      <td>61</td>\n",
       "      <td>white</td>\n",
       "      <td>daniamurashov</td>\n",
       "      <td>1439</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1454</td>\n",
       "      <td>-15</td>\n",
       "      <td>D02</td>\n",
       "      <td>Queen's Pawn Game: Zukertort Variation</td>\n",
       "      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-29 18:06:40</td>\n",
       "      <td>95</td>\n",
       "      <td>white</td>\n",
       "      <td>nik221107</td>\n",
       "      <td>1523</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1469</td>\n",
       "      <td>54</td>\n",
       "      <td>C41</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019415</th>\n",
       "      <td>2016-07-10 14:38:59</td>\n",
       "      <td>32</td>\n",
       "      <td>black</td>\n",
       "      <td>Alexandersasa</td>\n",
       "      <td>1590</td>\n",
       "      <td>Artur__Sergeevi4</td>\n",
       "      <td>1400</td>\n",
       "      <td>190</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening</td>\n",
       "      <td>g3 d5 Bg2 d4 e3 e5 exd4 exd4 Qe2 Be6 Bxb7 d3 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019416</th>\n",
       "      <td>2016-07-28 00:23:42</td>\n",
       "      <td>57</td>\n",
       "      <td>white</td>\n",
       "      <td>hakumen</td>\n",
       "      <td>1336</td>\n",
       "      <td>AliaBR</td>\n",
       "      <td>1170</td>\n",
       "      <td>166</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>e3 d5 Qf3 d4 Bc4 Nh6 exd4 Qxd4 Na3 Qe5 Ne2 a6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019417</th>\n",
       "      <td>2016-07-30 16:46:16</td>\n",
       "      <td>71</td>\n",
       "      <td>white</td>\n",
       "      <td>bed</td>\n",
       "      <td>1773</td>\n",
       "      <td>justdom</td>\n",
       "      <td>1094</td>\n",
       "      <td>679</td>\n",
       "      <td>B02</td>\n",
       "      <td>Alekhine Defense: Two Pawn Attack</td>\n",
       "      <td>e4 Nf6 e5 Nd5 c4 Nb6 d4 Nxc4 Bxc4 e6 Nf3 Bb4 B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019418</th>\n",
       "      <td>2016-07-27 21:32:30</td>\n",
       "      <td>82</td>\n",
       "      <td>black</td>\n",
       "      <td>Zeitfuge</td>\n",
       "      <td>1866</td>\n",
       "      <td>Sarm</td>\n",
       "      <td>2039</td>\n",
       "      <td>-173</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>e3 Nf6 c4 g6 Nf3 Bg7 d4 O-O Nc3 b6 Bd3 Bb7 O-O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019419</th>\n",
       "      <td>2016-07-08 14:14:40</td>\n",
       "      <td>121</td>\n",
       "      <td>white</td>\n",
       "      <td>smndvd</td>\n",
       "      <td>1730</td>\n",
       "      <td>zazpiak_1</td>\n",
       "      <td>1718</td>\n",
       "      <td>12</td>\n",
       "      <td>C41</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>e4 e5 Nf3 d6 d4 Bg4 Be2 Bxf3 Bxf3 Nf6 dxe5 dxe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1019420 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at turns winner       white_id white_rating  \\\n",
       "0       2017-08-31 20:06:40    13  white       bourgris         1500   \n",
       "1       2017-08-30 21:53:20    16  black           a-00         1322   \n",
       "2       2017-08-30 21:53:20    61  white         ischia         1496   \n",
       "3       2017-08-30 16:20:00    61  white  daniamurashov         1439   \n",
       "4       2017-08-29 18:06:40    95  white      nik221107         1523   \n",
       "...                     ...   ...    ...            ...          ...   \n",
       "1019415 2016-07-10 14:38:59    32  black  Alexandersasa         1590   \n",
       "1019416 2016-07-28 00:23:42    57  white        hakumen         1336   \n",
       "1019417 2016-07-30 16:46:16    71  white            bed         1773   \n",
       "1019418 2016-07-27 21:32:30    82  black       Zeitfuge         1866   \n",
       "1019419 2016-07-08 14:14:40   121  white         smndvd         1730   \n",
       "\n",
       "                 black_id black_rating rating_difference opening_eco  \\\n",
       "0                    a-00         1191               309         D10   \n",
       "1               skinnerua         1261                61         B00   \n",
       "2                    a-00         1500                -4         C20   \n",
       "3            adivanov2009         1454               -15         D02   \n",
       "4            adivanov2009         1469                54         C41   \n",
       "...                   ...          ...               ...         ...   \n",
       "1019415  Artur__Sergeevi4         1400               190         A00   \n",
       "1019416            AliaBR         1170               166         A00   \n",
       "1019417           justdom         1094               679         B02   \n",
       "1019418              Sarm         2039              -173         A00   \n",
       "1019419         zazpiak_1         1718                12         C41   \n",
       "\n",
       "                                   opening_name  \\\n",
       "0              Slav Defense: Exchange Variation   \n",
       "1        Nimzowitsch Defense: Kennedy Variation   \n",
       "2         King's Pawn Game: Leonardis Variation   \n",
       "3        Queen's Pawn Game: Zukertort Variation   \n",
       "4                              Philidor Defense   \n",
       "...                                         ...   \n",
       "1019415                       Hungarian Opening   \n",
       "1019416                    Van't Kruijs Opening   \n",
       "1019417       Alekhine Defense: Two Pawn Attack   \n",
       "1019418                    Van't Kruijs Opening   \n",
       "1019419                        Philidor Defense   \n",
       "\n",
       "                                                     moves  \n",
       "0        d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4 Nc3 Ba5 Bf4  \n",
       "1        d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...  \n",
       "2        e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...  \n",
       "3        d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...  \n",
       "4        e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...  \n",
       "...                                                    ...  \n",
       "1019415  g3 d5 Bg2 d4 e3 e5 exd4 exd4 Qe2 Be6 Bxb7 d3 c...  \n",
       "1019416  e3 d5 Qf3 d4 Bc4 Nh6 exd4 Qxd4 Na3 Qe5 Ne2 a6 ...  \n",
       "1019417  e4 Nf6 e5 Nd5 c4 Nb6 d4 Nxc4 Bxc4 e6 Nf3 Bb4 B...  \n",
       "1019418  e3 Nf6 c4 g6 Nf3 Bg7 d4 O-O Nc3 b6 Bd3 Bb7 O-O...  \n",
       "1019419  e4 e5 Nf3 d6 d4 Bg4 Be2 Bxf3 Bxf3 Nf6 dxe5 dxe...  \n",
       "\n",
       "[1019420 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull tables from SQL into a dataframe\n",
    "chess_df= pd.read_sql_table (\"chess_data\",conn)\n",
    "chess_df.drop(['id','index'],axis=1, inplace=True)\n",
    "chess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71b14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split moves column into moves df\n",
    "moves_df = chess_df['moves'].str.split(' ', n=10, expand=True)\n",
    "\n",
    "# Drop column 10 and rename columns\n",
    "moves_df=moves_df.drop(10,axis=1)\n",
    "moves_df.columns= [\"Wm1\",\"Bm1\",\"Wm2\",\"Bm2\",\"Wm3\",\"Bm3\",\"Wm4\",\"Bm4\",\"Wm5\",\"Bm5\"]\n",
    "\n",
    "moves_df[\"outcome\"] = chess_df[\"winner\"]\n",
    "\n",
    "# drop na\n",
    "moves_df = moves_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b95aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wm1 Bm1 Wm2 Bm2 Wm3 Bm3 Wm4 Bm4 Wm5 Bm5 outcome "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wm1</th>\n",
       "      <th>Bm1</th>\n",
       "      <th>Wm2</th>\n",
       "      <th>Bm2</th>\n",
       "      <th>Wm3</th>\n",
       "      <th>Bm3</th>\n",
       "      <th>Wm4</th>\n",
       "      <th>Bm4</th>\n",
       "      <th>Wm5</th>\n",
       "      <th>Bm5</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>222</td>\n",
       "      <td>15</td>\n",
       "      <td>379</td>\n",
       "      <td>361</td>\n",
       "      <td>273</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>179</td>\n",
       "      <td>314</td>\n",
       "      <td>149</td>\n",
       "      <td>254</td>\n",
       "      <td>307</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>124</td>\n",
       "      <td>37</td>\n",
       "      <td>123</td>\n",
       "      <td>116</td>\n",
       "      <td>24</td>\n",
       "      <td>258</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>143</td>\n",
       "      <td>162</td>\n",
       "      <td>9</td>\n",
       "      <td>239</td>\n",
       "      <td>302</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>88</td>\n",
       "      <td>124</td>\n",
       "      <td>260</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>445</td>\n",
       "      <td>327</td>\n",
       "      <td>607</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wm1  Bm1  Wm2  Bm2  Wm3  Bm3  Wm4  Bm4  Wm5  Bm5  outcome\n",
       "0   18    2   84   78  222   15  379  361  273   50        2\n",
       "1   18    3   85  105  179  314  149  254  307  262        0\n",
       "2   15   17   39  124   37  123  116   24  258  159        2\n",
       "3   18    2   88  143  162    9  239  302    4   53        2\n",
       "4   15   17   88  124  260   29    6  445  327  607        2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing moves to numbers\n",
    "for col in moves_df.columns:\n",
    "    print(col,end=' ')\n",
    "    \n",
    "    # Get list of unique values\n",
    "    values = list(set(moves_df[col].values))\n",
    "    \n",
    "    # Create numerical dictionary\n",
    "    values_with_indexes = {}\n",
    "    for i, v in enumerate(values):\n",
    "        values_with_indexes[v] = i\n",
    "    \n",
    "    # Replace column\n",
    "    moves_df.replace({col: values_with_indexes},inplace=True)\n",
    "\n",
    "moves_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4676791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv containing sample data to be imported into ML\n",
    "moves_df.to_csv(\"../datasets/ML/ML_sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7775660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = moves_df[\"outcome\"].values\n",
    "X = moves_df.drop(\"outcome\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 1)\n",
    "number_input_features = len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f988d3a0",
   "metadata": {},
   "source": [
    "# Stage 1 - Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec165a",
   "metadata": {},
   "source": [
    "### Model 1: sigmoid input, sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fcd9556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4553fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0cd86fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6836 - acc: 0.4972\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa44f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818634756792873, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45ff92",
   "metadata": {},
   "source": [
    "### Model 2: relu input, sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d12f88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a544ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "70bb859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.9443 - acc: 0.4878\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7437 - acc: 0.4869\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7417 - acc: 0.4884\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7347 - acc: 0.4879\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7300 - acc: 0.4890\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dfea5af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6922 - acc: 0.4983\n",
      "Loss: 0.6922125508361225, Accuracy: 0.49832427501678467\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93283ffe",
   "metadata": {},
   "source": [
    "### Model 3: tanh input, sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4cfef554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c012f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6439059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6830 - acc: 0.4972\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fd3a070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818692683180706, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79faa84",
   "metadata": {},
   "source": [
    "### Model 4: sigmoid input, linear output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ce5b4328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "439e20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab4c148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6861 - acc: 0.4974\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6824 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6824 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6828 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6834 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "486f7115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6826 - acc: 0.4983\n",
      "Loss: 0.6825688758876884, Accuracy: 0.4983282685279846\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616cfdc6",
   "metadata": {},
   "source": [
    "### Model 5: relu input, linear output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1957ae38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fdeb9efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "38d1fe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 7.0347 - acc: 0.4899\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5239 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5240 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5240 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5240 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0135088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 6.5152 - acc: 0.4983\n",
      "Loss: 6.51520274151468, Accuracy: 0.49834415316581726\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6f567",
   "metadata": {},
   "source": [
    "### Model 6: tanh input, linear output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab1db215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "526af93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "66a40f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.9183 - acc: 0.4969\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6825 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6825 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6825 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6824 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1e967743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6820 - acc: 0.4983\n",
      "Loss: 0.6819516978605651, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70397886",
   "metadata": {},
   "source": [
    "# Stage 1 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd6bc6",
   "metadata": {},
   "source": [
    "For the first stage of this analysis, we tried 6 models of varying parameters. The loss, accuracy scores, and parameters of our 6 models are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 2 | 0.6922 | 0.4983 | Relu input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 3 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 4 | 0.6826 | 0.4983 | Sigmoid input with 5 nodes, linear output, 5 epochs |\n",
    "| 5 | 6.5152 | 0.4983 | Relu input wiht 5 nodes, linear output, 5 epochs |\n",
    "| 6 | 0.6820 | 0.4983 | Tanh input with 5 nodes, linear output, 5 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3a887",
   "metadata": {},
   "source": [
    "The accuracy score for all 6 models was identical at 0.4983. An accuracy score of exactly 0.5 is the probability of randomly guessing the correct winner of a given game of chess, so the accuracy score of our models may reflect the difficulty of predicting a winner from only the first 10 moves of a game. Since games typically last far longer than 10 turns and the possible combinations of moves grow increasingly complex, this is not a surprising conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa3cfcf",
   "metadata": {},
   "source": [
    "Loss function, on the other hand, was not constant. The two models with relu inputs (Models 2 and 5) had the greatest loss score, indicating that the relu activation function is likely not the best choice for our model. Additionally, the models with sigmoid outputs (Models 1, 2, and 3) had lower loss functions than their counterpart models with linear outputs (Models 4, 5, and 6 respectively). This is expected, as output from a sigmoid function tends to be very close to either 0 or 1. We are posing a question with a binary answer, so a sigmoid function is the best choice for an activation function for our output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39143be",
   "metadata": {},
   "source": [
    "Given this information, our course of action for the final steps of completing this model will be to explore more varied input layers. This will be accomplished by varying the activation function (using sigmoid and tanh, leaving relu out), number of layers, number of nodes within each layer, and number of epochs used to train the model. We hypothesize that the sigmoid activation function will be the more appropriate choice for the input layer(s) for the same reasons it is the best choice for the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb1f82",
   "metadata": {},
   "source": [
    "# Stage 2 - Refining the model by adding an additional input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea826855",
   "metadata": {},
   "source": [
    "### Model 7 - sigmoid + sigmoid input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c2929f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mulle\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd5b1eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mulle\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc0efe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6822 - acc: 0.4975\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4b143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.681683825464082, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05205997",
   "metadata": {},
   "source": [
    "### Model 8 - sigmoid + tanh input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98efdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "780b6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20097c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6826 - acc: 0.4974\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "145642e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818749250321505, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cfe2e1",
   "metadata": {},
   "source": [
    "### Model 9 - tanh + sigmoid input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e65426f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "577c7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c1edfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d9107ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6816 - acc: 0.4983\n",
      "Loss: 0.6815962515790198, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf298e7",
   "metadata": {},
   "source": [
    "### Model 10 - tanh + tanh input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6134e99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "999d99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aa8c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6826 - acc: 0.4973\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea3f477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.6816705080182166, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa68ca",
   "metadata": {},
   "source": [
    "# Stage 2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48dd2b9",
   "metadata": {},
   "source": [
    "The next step of our analysis was to determine whether adding an additional input layer would assist in lowering loss or raising accuracy in our model. The loss, accuracy, and parameters for Models 7-10 are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 7 | 0.6817 | 0.4983 | Two sigmoid input layers with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 8 | 0.6919 | 0.4983 | Sigmoid first input layer and tanh second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 9 | 0.6816 | 0.4983 | Tanh first input layer and sigmoid second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 10 | 0.6817 | 0.4983 | Two tanh input layers with 5 nodes each, sigmoid output, 5 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b203ec3",
   "metadata": {},
   "source": [
    "Accuracy continued to remain constant across all models, even when an additional input layer was added. Loss varied slightly, but not to a significant extent; the greatest difference in loss between the best models from Stage 1 and Stage 2 was 0.0003. As such, we can conclude that adding a second input layer is not likely to significantly improve the ability of our machine learning model to predict the winner of a chess game from the first 10 moves. Additionally, we cannot draw any further conclusions regarding the efficacy of the sigmoid and tanh activation functions in input layers given the very similar results between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aafccd0",
   "metadata": {},
   "source": [
    "# Stage 3 - Refining the model by varying the number of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba96767",
   "metadata": {},
   "source": [
    "### Model 11 - sigmoid input layer, 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af5c34b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=2, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "293becc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24858675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6822 - acc: 0.4975\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4977\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78a52200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.6817401380583206, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ae3b6",
   "metadata": {},
   "source": [
    "### Model 12 - sigmoid input layer, 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43133a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1df64e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d98a1b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6838 - acc: 0.4972\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4977\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5308b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4984\n",
      "Loss: 0.6816825410157995, Accuracy: 0.4983521103858948\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a93e48",
   "metadata": {},
   "source": [
    "### Model 13 - tanh input layer, 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da0ebf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=2, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6cbceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "973ce938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6866 - acc: 0.4967\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f5faeed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6818 - acc: 0.4983\n",
      "Loss: 0.6818061287186948, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e826d",
   "metadata": {},
   "source": [
    "### Model 14 - tanh input layer, 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b6f5faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ea54df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "704954f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6844 - acc: 0.4973\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfc5a464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6818 - acc: 0.4983\n",
      "Loss: 0.6818064010055367, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58ac71",
   "metadata": {},
   "source": [
    "# Stage 3 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5666c",
   "metadata": {},
   "source": [
    "To determine whether the number of nodes affected the performance of our models, we ran single-layer models with varied numbers of nodes. The loss, accuracy, and parameters for Models 11-14 (as well as Models 1 and 3 for comparison) are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 11 | 0.6817 | 0.4983 | Sigmoid input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 12 | 0.6817 | 0.4984 | Sigmoid input with 8 nodes, sigmoid output, 5 epochs |\n",
    "| 3 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 13 | 0.6818 | 0.4983 | Tanh input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 14 | 0.6818 | 0.4983 | Tanh input with 8 nodes, sigmoid output, 5 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4350a49",
   "metadata": {},
   "source": [
    "Once again, loss and accuracy are more or less uniform. Model 12 is the first to show an accuracy score different from any other model, but a difference of 0.0001 is not significant. Given the results of Stage 3, we are unable to attribute number of nodes to model performance. Sigmoid and tanh input layers also continue to show no appreciable difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9e201",
   "metadata": {},
   "source": [
    "# Stage 4 - Refining the model by adjusting the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f20646",
   "metadata": {},
   "source": [
    "### Model 15 - sigmoid input layer, 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17ed3407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c846a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00824415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6830 - acc: 0.4975\n",
      "Epoch 2/2\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df0878ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.6817277191875162, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b751976",
   "metadata": {},
   "source": [
    "### Model 16 - sigmoid input layer, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c557ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "310a01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25c82a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6841 - acc: 0.4969\n",
      "Epoch 2/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 6/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 7/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 8/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6818 - acc: 0.4976\n",
      "Epoch 9/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4977\n",
      "Epoch 10/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "579b2229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6816 - acc: 0.4983\n",
      "Loss: 0.6815956441493135, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74789873",
   "metadata": {},
   "source": [
    "### Model 17 - tanh input layer, 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4894ca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b567976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46838401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6862 - acc: 0.4969\n",
      "Epoch 2/2\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4977\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0116c08a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818530754724361, Accuracy: 0.49834415316581726\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032ed87",
   "metadata": {},
   "source": [
    "### Model 18 - tanh input layer, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "190f0722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c00ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e974ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6832 - acc: 0.4973\n",
      "Epoch 2/10\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 4/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 6/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 7/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 8/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 9/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 10/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "560cd004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6818 - acc: 0.4983\n",
      "Loss: 0.6818354549266634, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c6259",
   "metadata": {},
   "source": [
    "# Stage 4 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c36319",
   "metadata": {},
   "source": [
    "Finally, we tested the effect of number of epochs on model performance. The loss, accuracy, and parameters for Models 15-18 (as well as Models 1 and 3 for comparison) are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 15 | 0.6817 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 16 | 0.6816 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 10 epochs |\n",
    "| 3 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 17 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 18 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 10 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ab195",
   "metadata": {},
   "source": [
    "As with all other parameters, adjusting the number of epochs had little to no impact on the performance of our machine learning models. Input function continued to show no impact as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117537f3",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192793f9",
   "metadata": {},
   "source": [
    "For reference, the loss, accuracy, and parameters for all models are shown again below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 2 | 0.6922 | 0.4983 | Relu input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 3 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 4 | 0.6826 | 0.4983 | Sigmoid input with 5 nodes, linear output, 5 epochs |\n",
    "| 5 | 6.5152 | 0.4983 | Relu input wiht 5 nodes, linear output, 5 epochs |\n",
    "| 6 | 0.6820 | 0.4983 | Tanh input with 5 nodes, linear output, 5 epochs |\n",
    "| 7 | 0.6817 | 0.4983 | Two sigmoid input layers with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 8 | 0.6919 | 0.4983 | Sigmoid first input layer and tanh second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 9 | 0.6816 | 0.4983 | Tanh first input layer and sigmoid second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 10 | 0.6817 | 0.4983 | Two tanh input layers with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 11 | 0.6817 | 0.4983 | Sigmoid input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 12 | 0.6817 | 0.4984 | Sigmoid input with 8 nodes, sigmoid output, 5 epochs |\n",
    "| 13 | 0.6818 | 0.4983 | Tanh input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 14 | 0.6818 | 0.4983 | Tanh input with 8 nodes, sigmoid output, 5 epochs |\n",
    "| 15 | 0.6817 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 16 | 0.6816 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 10 epochs |\n",
    "| 17 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 18 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 10 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2eb2c4",
   "metadata": {},
   "source": [
    "All four stages of this analysis showed that varying the parameters of our machine learning model had virtually no impact on both loss and accuracy. We were only able to draw conclusions regarding two of the five parameters examined: ruling out relu as an activation function and determining that sigmoid is the most appropriate output function. No conclusive evidence was found for the other three parameters. A summary of results can be found in the table below:\n",
    "\n",
    "| Parameter | Findings |\n",
    "| :---- | :--- | \n",
    "| Activation function | Relu ruled out, no evidence that either sigmoid or tanh is better than the other |\n",
    "| Output function | Sigmoid deemed better than linear |\n",
    "| Number of layers | No evidence that either 1 layer or 2 layers is better than the other |\n",
    "| Number of nodes | No evidence that any of 2, 5, or 8 nodes is better than the others |\n",
    "| Number of epochs | No evidence that any of 2, 5, or 10 epochs is better than the others |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dffc433",
   "metadata": {},
   "source": [
    "All in all, the results of this study point to neural networks not being an effective means of predicting the winner of a game of chess given the first 10 moves. We supposed this was the case following the Stage 1 analysis, and Stages 2-4 supported the hypothesis. We cannot conclusively say that a neural network is entirely ineffective when trying to answer the question posed in this project since there are still many more combinations of parameters that could be tested, but the 18 models we examined gave us little reason to believe this is a path worth following.\n",
    "\n",
    "As previously stated, chess is a complex game. The possible outcomes are difficult to map as each individual move begets an exponentially branching tree of possibilities. Since games of chess tend to last far longer than 10 turns, our analysis is only able to scratch the surface. We were limited by a number of factors, most notably time and computing power. In theory, we could have extended our analysis far past the first 10 turns. However, adding an extra turn creates another branch on the tree and multiplies the number of computations necessary to perform this analysis. As such, we decided to examine whether determining a winner given 10 turns is possible with resources accessible to a wider range of people. Since accuracy scores remained very close to the probability of guessing a winner entirely at random throughout the entire project, the ultimate answer to our question is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f916650",
   "metadata": {},
   "source": [
    "# Future Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de7bae",
   "metadata": {},
   "source": [
    "The only type of machine learning used in this project was a neural network. While this method proved ineffective, other types of machine learning may be more useful in answering our question. For example, the flow of a game of chess closely mimics a quickly branching set of choices ultimately culminating in a winner. A decision tree may be an interesting way to map out chess games, though said tree would have to be almost impossibly large to accurately capture every possible combination of moves in a game of chess.\n",
    "\n",
    "Principal Component Analysis could possibly be used to incorporate more than 10 turns into the study without the number of input features reaching a problematically large number. This may be difficult given the qualitative nature of our input data, but it is an avenue to be explored.\n",
    "\n",
    "Finally, a repetition of our analysis with more input features could be performed given more time and access to faster computing. It is not realistic for a student using a personal computer to perform this analysis with the first 50 turns of a game of chess using a sufficiently large dataset since it would likely take too long and use up too many resources, but given enough time and computing power, this could either corroborate our conclusions or show that neural networks may be viable solution after all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
