{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e801ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import db_password\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import pandas.io.sql as sqlio\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c07c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create database connection variable \n",
    "conn = psycopg2.connect(user=\"postgres\", password=db_password, host=\"localhost\", database=\"lichess_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc714d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute query and save it to a variable\n",
    "query=\"select * from chess_data\"\n",
    "chess_df = sqlio.read_sql_query(query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b8823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_df.drop(['id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c71b14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split moves column into moves df\n",
    "moves_df = chess_df['moves'].str.split(' ', n=10, expand=True)\n",
    "\n",
    "# Drop column 10 and rename columns\n",
    "moves_df=moves_df.drop(10,axis=1)\n",
    "moves_df.columns= [\"Wm1\",\"Bm1\",\"Wm2\",\"Bm2\",\"Wm3\",\"Bm3\",\"Wm4\",\"Bm4\",\"Wm5\",\"Bm5\"]\n",
    "\n",
    "moves_df[\"outcome\"] = chess_df[\"winner\"]\n",
    "\n",
    "# drop na\n",
    "moves_df = moves_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b95aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wm1 Bm1 Wm2 Bm2 Wm3 Bm3 Wm4 Bm4 Wm5 Bm5 outcome "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wm1</th>\n",
       "      <th>Bm1</th>\n",
       "      <th>Wm2</th>\n",
       "      <th>Bm2</th>\n",
       "      <th>Wm3</th>\n",
       "      <th>Bm3</th>\n",
       "      <th>Wm4</th>\n",
       "      <th>Bm4</th>\n",
       "      <th>Wm5</th>\n",
       "      <th>Bm5</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>162</td>\n",
       "      <td>242</td>\n",
       "      <td>267</td>\n",
       "      <td>426</td>\n",
       "      <td>133</td>\n",
       "      <td>634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>150</td>\n",
       "      <td>184</td>\n",
       "      <td>30</td>\n",
       "      <td>411</td>\n",
       "      <td>282</td>\n",
       "      <td>330</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>144</td>\n",
       "      <td>99</td>\n",
       "      <td>283</td>\n",
       "      <td>392</td>\n",
       "      <td>370</td>\n",
       "      <td>105</td>\n",
       "      <td>489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "      <td>114</td>\n",
       "      <td>229</td>\n",
       "      <td>51</td>\n",
       "      <td>381</td>\n",
       "      <td>374</td>\n",
       "      <td>565</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>144</td>\n",
       "      <td>299</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>253</td>\n",
       "      <td>267</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wm1  Bm1  Wm2  Bm2  Wm3  Bm3  Wm4  Bm4  Wm5  Bm5  outcome\n",
       "0   17   14   60   34  162  242  267  426  133  634        1\n",
       "1   17   11   77  150  184   30  411  282  330  410        0\n",
       "2    3    7   36  144   99  283  392  370  105  489        1\n",
       "3   17   14   84  114  229   51  381  374  565   15        1\n",
       "4    3    7   84  144  299   11   16  253  267  639        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing moves to numbers\n",
    "for col in moves_df.columns:\n",
    "    print(col,end=' ')\n",
    "    \n",
    "    # Get list of unique values\n",
    "    values = list(set(moves_df[col].values))\n",
    "    \n",
    "    # Create numerical dictionary\n",
    "    values_with_indexes = {}\n",
    "    for i, v in enumerate(values):\n",
    "        values_with_indexes[v] = i\n",
    "    \n",
    "    # Replace column\n",
    "    moves_df.replace({col: values_with_indexes},inplace=True)\n",
    "\n",
    "moves_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4676791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv containing sample data to be imported into ML\n",
    "# moves_df.to_csv(\"ML_sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7775660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = moves_df[\"outcome\"].values\n",
    "X = moves_df.drop(\"outcome\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 1)\n",
    "number_input_features = len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c57944",
   "metadata": {},
   "source": [
    "# Stage 1 - Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec165a",
   "metadata": {},
   "source": [
    "### Model 1: sigmoid input, sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fcd9556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4553fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0cd86fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6836 - acc: 0.4972\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa44f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818634756792873, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45ff92",
   "metadata": {},
   "source": [
    "### Model 2: relu input, sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d12f88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a544ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "70bb859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.9443 - acc: 0.4878\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7437 - acc: 0.4869\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7417 - acc: 0.4884\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7347 - acc: 0.4879\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.7300 - acc: 0.4890\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dfea5af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6922 - acc: 0.4983\n",
      "Loss: 0.6922125508361225, Accuracy: 0.49832427501678467\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93283ffe",
   "metadata": {},
   "source": [
    "### Model 3: tanh input, sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4cfef554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c012f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6439059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6830 - acc: 0.4972\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fd3a070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818692683180706, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79faa84",
   "metadata": {},
   "source": [
    "### Model 4: sigmoid input, linear output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ce5b4328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "439e20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab4c148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6861 - acc: 0.4974\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6824 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6824 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6828 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6834 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "486f7115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6826 - acc: 0.4983\n",
      "Loss: 0.6825688758876884, Accuracy: 0.4983282685279846\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616cfdc6",
   "metadata": {},
   "source": [
    "### Model 5: relu input, linear output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1957ae38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fdeb9efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "38d1fe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 7.0347 - acc: 0.4899\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5239 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5240 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5240 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 6.5240 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0135088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 6.5152 - acc: 0.4983\n",
      "Loss: 6.51520274151468, Accuracy: 0.49834415316581726\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6f567",
   "metadata": {},
   "source": [
    "### Model 6: tanh input, linear output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab1db215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "526af93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "66a40f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.9183 - acc: 0.4969\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6825 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6825 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6825 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 11s 15us/sample - loss: 0.6824 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1e967743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6820 - acc: 0.4983\n",
      "Loss: 0.6819516978605651, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7123863",
   "metadata": {},
   "source": [
    "# Stage 1 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd6bc6",
   "metadata": {},
   "source": [
    "For the first stage of this analysis, we tried 6 models of varying parameters. The loss, accuracy scores, and parameters of our 6 models are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 2 | 0.6922 | 0.4983 | Relu input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 3 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 4 | 0.6826 | 0.4983 | Sigmoid input with 5 nodes, linear output, 5 epochs |\n",
    "| 5 | 6.5152 | 0.4983 | Relu input wiht 5 nodes, linear output, 5 epochs |\n",
    "| 6 | 0.6820 | 0.4983 | Tanh input with 5 nodes, linear output, 5 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3a887",
   "metadata": {},
   "source": [
    "The accuracy score for all 6 models was identical at 0.4983. An accuracy score of exactly 0.5 is the probability of randomly guessing the correct winner of a given game of chess, so the accuracy score of our models may reflect the difficulty of predicting a winner from only the first 10 moves of a game. Since games typically last far longer than 10 turns and the possible combinations of moves grow increasingly complex, this is not a surprising conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa3cfcf",
   "metadata": {},
   "source": [
    "Loss function, on the other hand, was not constant. The two models with relu inputs (Models 2 and 5) had the greatest loss score, indicating that the relu activation function is likely not the best choice for our model. Additionally, the models with sigmoid outputs (Models 1, 2, and 3) had lower loss functions than their counterpart models with linear outputs (Models 4, 5, and 6 respectively). This is expected, as output from a sigmoid function tends to be very close to either 0 or 1. We are posing a question with a binary answer, so a sigmoid function is the best choice for an activation function for our output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39143be",
   "metadata": {},
   "source": [
    "Given this information, our course of action for the final steps of completing this model will be to explore more varied input layers. This will be accomplished by varying the activation function (using sigmoid and tanh, leaving relu out), number of layers, number of nodes within each layer, and number of epochs used to train the model. We hypothesize that the sigmoid activation function will be the more appropriate choice for the input layer(s) for the same reasons it is the best choice for the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04f401",
   "metadata": {},
   "source": [
    "# Stage 2 - Refining the model by adding an additional input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571dfb40",
   "metadata": {},
   "source": [
    "### Model 7 - sigmoid + sigmoid input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271c8849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mulle\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ee711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mulle\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ac97d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6822 - acc: 0.4975\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f8dbe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.681683825464082, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf325cf",
   "metadata": {},
   "source": [
    "### Model 8 - sigmoid + tanh input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e70cb8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a8f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dbe781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6826 - acc: 0.4974\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a1cfb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818749250321505, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee7f1d",
   "metadata": {},
   "source": [
    "### Model 9 - tanh + sigmoid input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfcc5b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7dac166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4823be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8828267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6816 - acc: 0.4983\n",
      "Loss: 0.6815962515790198, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8503f0f",
   "metadata": {},
   "source": [
    "### Model 10 - tanh + tanh input layers, 5 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a34c2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4d09b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2c15d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6826 - acc: 0.4973\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ab7636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.6816705080182166, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2fe30e",
   "metadata": {},
   "source": [
    "# Stage 2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2208d",
   "metadata": {},
   "source": [
    "The next step of our analysis was to determine whether adding an additional input layer would assist in lowering loss or raising accuracy in our model. The loss, accuracy, and parameters for Models 7-10 are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 7 | 0.6817 | 0.4983 | Two sigmoid input layers with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 8 | 0.6919 | 0.4983 | Sigmoid first input layer and tanh second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 9 | 0.6816 | 0.4983 | Tanh first input layer and sigmoid second input layer with 5 nodes each, sigmoid output, 5 epochs |\n",
    "| 10 | 0.6817 | 0.4983 | Two tanh input layers with 5 nodes each, sigmoid output, 5 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035704c2",
   "metadata": {},
   "source": [
    "Accuracy continued to remain constant across all models, even when an additional input layer was added. Loss varied slightly, but not to a significant extent; the greatest difference in loss between the best models from Stage 1 and Stage 2 was 0.0003. As such, we can conclude that adding a second input layer is not likely to significantly improve the ability of our machine learning model to predict the winner of a chess game from the first 10 moves. Additionally, we cannot draw any further conclusions regarding the efficacy of the sigmoid and tanh activation functions in input layers given the very similar results between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc9dbc",
   "metadata": {},
   "source": [
    "# Stage 3 - Refining the model by varying the number of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907a5eb1",
   "metadata": {},
   "source": [
    "### Model 11 - sigmoid input layer, 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19382354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=2, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a34cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b7b2bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6822 - acc: 0.4975\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4977\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9f31890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.6817401380583206, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cbc61",
   "metadata": {},
   "source": [
    "### Model 12 - sigmoid input layer, 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e79bb9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56e2a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13844f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6838 - acc: 0.4972\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4977\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b54a6d15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4984\n",
      "Loss: 0.6816825410157995, Accuracy: 0.4983521103858948\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de14664",
   "metadata": {},
   "source": [
    "### Model 13 - tanh input layer, 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77c77640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=2, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "869524cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "120e93af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6866 - acc: 0.4967\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a127414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6818 - acc: 0.4983\n",
      "Loss: 0.6818061287186948, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d0cc15",
   "metadata": {},
   "source": [
    "### Model 14 - tanh input layer, 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60814528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c1b7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7525dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6844 - acc: 0.4973\n",
      "Epoch 2/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/5\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 4/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/5\n",
      "754604/754604 [==============================] - 9s 12us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf22494b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6818 - acc: 0.4983\n",
      "Loss: 0.6818064010055367, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0828825a",
   "metadata": {},
   "source": [
    "# Stage 3 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29a711b",
   "metadata": {},
   "source": [
    "To determine whether the number of nodes affected the performance of our models, we ran single-layer models with varied numbers of nodes. The loss, accuracy, and parameters for Models 11-14 (as well as Models 1 and 3 for comparison) are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 11 | 0.6817 | 0.4983 | Sigmoid input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 12 | 0.6817 | 0.4984 | Sigmoid input with 8 nodes, sigmoid output, 5 epochs |\n",
    "| 3 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 13 | 0.6818 | 0.4983 | Tanh input with 2 nodes, sigmoid output, 5 epochs |\n",
    "| 14 | 0.6818 | 0.4983 | Tanh input with 8 nodes, sigmoid output, 5 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e59fc4",
   "metadata": {},
   "source": [
    "Once again, loss and accuracy are more or less uniform. Model 12 is the first to show an accuracy score different from any other model, but a difference of 0.0001 is not significant. Given the results of Stage 3, we are unable to attribute number of nodes to model performance. Sigmoid and tanh input layers also continue to show no appreciable difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec2fb8",
   "metadata": {},
   "source": [
    "# Stage 4 - Refining the model by adjusting the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac7c94",
   "metadata": {},
   "source": [
    "### Model 15 - sigmoid input layer, 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c32fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76d820d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc0c8866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6830 - acc: 0.4975\n",
      "Epoch 2/2\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1c56b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6817 - acc: 0.4983\n",
      "Loss: 0.6817277191875162, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00dac5d",
   "metadata": {},
   "source": [
    "### Model 16 - sigmoid input layer, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d18a9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c82f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea972b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6841 - acc: 0.4969\n",
      "Epoch 2/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 3/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 4/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 5/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 6/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 7/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6819 - acc: 0.4976\n",
      "Epoch 8/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6818 - acc: 0.4976\n",
      "Epoch 9/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4977\n",
      "Epoch 10/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6818 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6e5beed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6816 - acc: 0.4983\n",
      "Loss: 0.6815956441493135, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc6695e",
   "metadata": {},
   "source": [
    "### Model 17 - tanh input layer, 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5430746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b756e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4eb692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6862 - acc: 0.4969\n",
      "Epoch 2/2\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4977\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19f8d100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6819 - acc: 0.4983\n",
      "Loss: 0.6818530754724361, Accuracy: 0.49834415316581726\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d690b",
   "metadata": {},
   "source": [
    "### Model 18 - tanh input layer, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78590915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the keras sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer including input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"tanh\", input_dim = number_input_features))\n",
    "\n",
    "# Add the ouput layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Create a summary to check the structure of the sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3dd8de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "425a9f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6832 - acc: 0.4973\n",
      "Epoch 2/10\n",
      "754604/754604 [==============================] - 11s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 3/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 4/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 5/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6820 - acc: 0.4976\n",
      "Epoch 6/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 7/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 8/10\n",
      "754604/754604 [==============================] - 10s 14us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 9/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n",
      "Epoch 10/10\n",
      "754604/754604 [==============================] - 10s 13us/sample - loss: 0.6821 - acc: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6740b46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251535/251535 - 2s - loss: 0.6818 - acc: 0.4983\n",
      "Loss: 0.6818354549266634, Accuracy: 0.4983481466770172\n"
     ]
    }
   ],
   "source": [
    "# now that our deep learning model is properly trained, we can evaluate the model's performance by testing its\n",
    "# predictive capabilities on our testing dataset\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141ab7f",
   "metadata": {},
   "source": [
    "# Stage 4 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e800609",
   "metadata": {},
   "source": [
    "Finally, we tested the effect of number of epochs on model performance. The loss, accuracy, and parameters for Models 15-18 (as well as Models 1 and 3 for comparison) are shown below:\n",
    "\n",
    "| Model | Loss | Accuracy | Parameters |\n",
    "| :---- | :--- | :------- | :--------- |\n",
    "| 1 | 0.6819 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 15 | 0.6817 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 16 | 0.6816 | 0.4983 | Sigmoid input with 5 nodes, sigmoid output, 10 epochs |\n",
    "| 3 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 5 epochs |\n",
    "| 17 | 0.6819 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 2 epochs |\n",
    "| 18 | 0.6818 | 0.4983 | Tanh input with 5 nodes, sigmoid output, 10 epochs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e0af2",
   "metadata": {},
   "source": [
    "As with all other parameters, adjusting the number of epochs had little to no impact on the performance of our machine learning models. Input function continued to show no impact as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c436b4c",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a942d2",
   "metadata": {},
   "source": [
    "For reference, the loss, accuracy, and parameters for all models are shown again below:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
